# -*- coding: utf-8 -*-
"""Time Series & Clustering

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VYCK5PCpStArXqvHMYaEfD7eNMsr2qva

#Time Series forecast Total Goods Sold

##Import Libraries
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import statsmodels.api as sm
from statsmodels.tsa.arima.model import ARIMA
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf

"""##Load Dataset"""

# Load the dataset
df = pd.read_csv('Case Study - Transaction.csv')
print(df)

#removing unnamed Column
df = df.drop(df.columns[df.columns.str.contains('Unnamed', case=False)], axis=1)
print(df)

#Selecting used Column
df[['Date', 'Qty']]
print(df)

"""##Creating aggregate daily transaction"""

df['Date'] = pd.to_datetime(df['Date'])
daily_quantity = df.groupby(df['Date'].dt.date)['Qty'].sum().reset_index()

# To display the results in the console
print(daily_quantity)

# To save the results to a new CSV file
daily_quantity.to_csv('daily_quantity_aggregated.csv', index=False)

"""##Stasionarity Check"""

df = pd.read_csv('daily_quantity_aggregated.csv')
df['Qty'].plot(figsize=(12,5))

from statsmodels.tsa.stattools import adfuller

def adf_test(dataset):
  dftest = adfuller(dataset, autolag = 'AIC')
  print("1. ADF : ",dftest[0])
  print("2. P-Value : ", dftest[1])
  print("3. Num Of Lags : ", dftest[2])
  print("4. Num Of Observations Used For ADF Regression and Critical Values Calculation :", dftest[3])
  print("5. Critical Values :")
  for key, val in dftest[4].items():
      print("\t",key, ": ", val)

adf_test(df['Qty'])

"""##Figure Out Order for ARIMA Model"""

from pmdarima import auto_arima
# Ignore harmless warnings
import warnings
warnings.filterwarnings("ignore")

stepwise_fit = auto_arima(df['Qty'],
                          suppress_warnings=True)

stepwise_fit.summary()

from statsmodels.tsa.arima_model import ARIMA

"""##Split Data into Training and Testing

"""

print(df.shape)
train=df.iloc[:-30]
test=df.iloc[-30:]
print(train.shape,test.shape)
print(test.iloc[0],test.iloc[-1])

from statsmodels.tsa.arima.model import ARIMA
model=ARIMA(train['Qty'],order=(1,0,5))
model=model.fit()
model.summary()

start=len(train)
end=len(train)+len(test)-1
#if the predicted values dont have date values as index, you will have to uncomment the following two commented lines to plot a graph
#index_future_dates=pd.date_range(start='2022-01-01',end='2022-12-31')
pred=model.predict(start=start,end=end,typ='levels').rename('ARIMA predictions')
print(pred)

"""##Future Date Prediction"""

#pred.index=index_future_dates
pred.plot(legend=True)
test['Qty'].plot(legend=True)

test['Qty'].mean()

from sklearn.metrics import mean_squared_error
from math import sqrt
rmse=sqrt(mean_squared_error(pred,test['Qty']))
print(rmse)

model2=ARIMA(df['Qty'],order=(1,0,5))
model2=model2.fit()
df.tail()

#prediction for 30 days
index_future_dates=pd.date_range(start='2022-12-31',end='2023-01-30')
#print(index_future_dates)
pred=model2.predict(start=len(df),end=len(df)+30,typ='levels').rename('ARIMA Predictions')
#print(comp_pred)
pred.index=index_future_dates
print(pred)

pred.plot(figsize=(12,5),legend=True)

"""# Clustering of Consumer Data (K-Means)

##Agregation of Product Sold and Costumer Dataset (Data Preparation)
"""

import pandas as pd

# Load the first dataset (transactions dataset)
df_transactions = pd.read_csv('Case Study - Transaction.csv')  # Replace with the actual file path

# Load the second dataset (customer dataset)
df_customers = pd.read_csv('Case Study - Customer.csv')  # Replace with the actual file path

# Merge the two datasets on the common column 'CustomerID'
merged_df = df_transactions.merge(df_customers, on='CustomerID', how='inner')

# Calculate the number of transactions per customer using groupby and count
transactions_per_customer = merged_df.groupby('CustomerID')['TransactionID'].count().reset_index()

# Rename the count column to 'TransactionCount'
transactions_per_customer.rename(columns={'TransactionID': 'TransactionCount'}, inplace=True)

# Calculate the total Qty and TotalAmount per customer using groupby and sum
total_qty_per_customer = merged_df.groupby('CustomerID')['Qty'].sum().reset_index()
total_amount_per_customer = merged_df.groupby('CustomerID')['TotalAmount'].sum().reset_index()

# Rename the sum columns
total_qty_per_customer.rename(columns={'Qty': 'TotalQty'}, inplace=True)
total_amount_per_customer.rename(columns={'TotalAmount': 'TotalAmountSum'}, inplace=True)

# Merge the transaction count, total Qty, and total TotalAmount back to the customer dataset
merged_with_counts = df_customers.merge(transactions_per_customer, on='CustomerID', how='left')
merged_with_counts = merged_with_counts.merge(total_qty_per_customer, on='CustomerID', how='left')
merged_with_counts = merged_with_counts.merge(total_amount_per_customer, on='CustomerID', how='left')

# Fill any NaN values in the merged dataset with 0 (if needed)
merged_with_counts.fillna(0, inplace=True)

# Now, merged_with_counts contains CustomerID along with transaction count, total Qty, and total TotalAmount per customer.

# To save the merged dataset with counts and totals to a new CSV file:
merged_with_counts.to_csv('merged_dataset_with_counts_and_totals.csv', index=False)  # Replace with the desired file path

# To inspect the first few rows of the merged dataset with counts and totals:
print(merged_with_counts.head())

"""##Import Libraries"""

# Import necessary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
import seaborn as sns

# Load the dataset
df= data = pd.read_csv('merged_dataset_with_counts_and_totals.csv')  # Replace 'your_dataset.csv' with the actual file path
print(df)

"""##Data Exploration"""

#Costumer Average Age
df.drop(["CustomerID"], axis = 1, inplace=True)

plt.figure(figsize=(10,6))
plt.title("Ages Frequency")
sns.axes_style("dark")
sns.violinplot(y=df["Age"])
plt.show()

#Costumer Average Income and Transaction Count
plt.figure(figsize=(15,6))
plt.subplot(1,2,1)
sns.boxplot(y=df["TransactionCount"], color="red")
plt.subplot(1,2,2)
sns.boxplot(y=df["Income"])
plt.show()

#Costumer Gender
Gender = df.Gender.value_counts()
sns.set_style("darkgrid")
plt.figure(figsize=(10,4))
sns.barplot(x=Gender.index, y=Gender.values)
plt.xticks([0, 1], ['Male', 'Female'])
plt.show()

#Costumer Age Gap
age18_25 = df.Age[(df.Age <= 25) & (df.Age >= 18)]
age26_35 = df.Age[(df.Age <= 35) & (df.Age >= 26)]
age36_45 = df.Age[(df.Age <= 45) & (df.Age >= 36)]
age46_55 = df.Age[(df.Age <= 55) & (df.Age >= 46)]
age55above = df.Age[df.Age >= 56]

x = ["18-25","26-35","36-45","46-55","55+"]
y = [len(age18_25.values),len(age26_35.values),len(age36_45.values),len(age46_55.values),len(age55above.values)]

plt.figure(figsize=(15,6))
sns.barplot(x=x, y=y, palette="rocket")
plt.title("Number of Customer and Ages")
plt.xlabel("Age")
plt.ylabel("Number of Customer")
plt.show()

"""##Calculating Optimal Number of Cluster"""

# Determine the optimal number of clusters using the Elbow Method
df.drop(["Marital Status"], axis = 1, inplace=True)
from sklearn.cluster import KMeans
wcss = []
for k in range(1,11):
    kmeans = KMeans(n_clusters=k, init="k-means++")
    kmeans.fit(df.iloc[:,1:])
    wcss.append(kmeans.inertia_)
plt.figure(figsize=(12,6))
plt.grid()
plt.plot(range(1,11),wcss, linewidth=2, color="red", marker ="8")
plt.xlabel("K Value")
plt.xticks(np.arange(1,11,1))
plt.ylabel("WCSS")
plt.show()

# Plot the Elbow Method graph

km = KMeans(n_clusters=3)
clusters = km.fit_predict(df.iloc[:,1:])
df["label"] = clusters

"""#Visualization of Clustering"""

from mpl_toolkits.mplot3d import Axes3D
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd

fig = plt.figure(figsize=(20,10))
ax = fig.add_subplot(111, projection='3d')
ax.scatter(df.Age[df.label == 0], df["Income"][df.label == 0], df["TransactionCount"][df.label == 0], c='blue', s=60)
ax.scatter(df.Age[df.label == 1], df["Income"][df.label == 1], df["TransactionCount"][df.label == 1], c='red', s=60)
ax.scatter(df.Age[df.label == 2], df["Income"][df.label == 2], df["TransactionCount"][df.label == 2], c='green', s=60)
ax.scatter(df.Age[df.label == 3], df["Income"][df.label == 3], df["TransactionCount"][df.label == 3], c='orange', s=60)
ax.scatter(df.Age[df.label == 4], df["Income"][df.label == 4], df["TransactionCount"][df.label == 4], c='purple', s=60)
ax.view_init(30, 185)
plt.xlabel("Age")
plt.ylabel("Income")
ax.set_zlabel('TransactionCount')
plt.show()

from mpl_toolkits.mplot3d import Axes3D
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd

fig = plt.figure(figsize=(20,10))
ax = fig.add_subplot(111, projection='3d')
ax.scatter(df.Gender[df.label == 0], df["Income"][df.label == 0], df["TotalQty"][df.label == 0], c='blue', s=60)
ax.scatter(df.Gender[df.label == 1], df["Income"][df.label == 1], df["TotalQty"][df.label == 1], c='red', s=60)
ax.scatter(df.Gender[df.label == 2], df["Income"][df.label == 2], df["TotalQty"][df.label == 2], c='green', s=60)
ax.scatter(df.Gender[df.label == 3], df["Income"][df.label == 3], df["TotalQty"][df.label == 3], c='orange', s=60)
ax.scatter(df.Gender[df.label == 4], df["Income"][df.label == 4], df["TotalQty"][df.label == 4], c='purple', s=60)
ax.view_init(30, 185)
plt.xlabel("Gender")
plt.ylabel("Income")
ax.set_zlabel('TotalQty')
plt.show()

sns.pairplot(df, vars = ['TransactionCount', 'TotalQty', 'TotalAmountSum'], hue = "Age")